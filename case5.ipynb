{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b13fb10",
   "metadata": {},
   "source": [
    "1 imagenet256のラベル付けを変更する \n",
    "\n",
    "2 imagenet_class_index_lower.jsonにimagenet-256のデータセットのラベルと会うように文字列を修正（手動＋コード）\n",
    "\n",
    "3 事前学習済みのresnet50を用いてimagenet-256のデータセットの画像分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf09dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] マッチできたクラス数: 999/1000\n",
      "[WARN] マッチできなかったクラス例: ['tank_suit'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 4218/4218 [12:06<00:00,  5.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 85.51%\n",
      "Top-5 Accuracy: 97.17%\n",
      "Top-1で正解した画像数: 461169\n",
      "Top-5で正解した画像数: 524073\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# 1. 前処理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# 2. データセット\n",
    "data_dir = \"./imagenet-256\"\n",
    "val_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# 3. モデル\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 4. ImageNet クラスインデックスを読み込み\n",
    "with open(\"imagenet_class_index_lower.json\", \"r\") as f:\n",
    "    class_idx = json.load(f)\n",
    "\n",
    "# name → index の辞書を作成（空白はアンダースコアに変換）\n",
    "name_to_idx = {}\n",
    "for k, v in class_idx.items():\n",
    "    idx = int(k)\n",
    "    synset, name = v\n",
    "    # \"afghan hound\" → \"afghan_hound\"\n",
    "    norm_name = name.replace(\" \", \"_\")\n",
    "    name_to_idx[norm_name] = idx\n",
    "\n",
    "# abc順 (val_dataset.classes) → ImageNetインデックス\n",
    "abc2idx = {}\n",
    "missing = []\n",
    "for cls_name in val_dataset.classes:\n",
    "    if cls_name in name_to_idx:\n",
    "        abc2idx[cls_name] = name_to_idx[cls_name]\n",
    "    else:\n",
    "        missing.append(cls_name)\n",
    "\n",
    "print(f\"[INFO] マッチできたクラス数: {len(abc2idx)}/{len(val_dataset.classes)}\")\n",
    "if missing:\n",
    "    print(f\"[WARN] マッチできなかったクラス例: {missing[:10]} ...\")\n",
    "\n",
    "# 5. 精度計算\n",
    "correct1, correct5, total = 0, 0, 0\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "correct_top1_paths = []\n",
    "correct_top5_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(tqdm(val_loader, desc=\"Evaluating\", unit=\"batch\")):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        valid_indices = []\n",
    "        valid_labels_idx = []\n",
    "        valid_paths = []\n",
    "        for i, l in enumerate(labels.cpu()):\n",
    "            cls_name = val_dataset.classes[l]\n",
    "            if cls_name in abc2idx:\n",
    "                valid_indices.append(i)\n",
    "                valid_labels_idx.append(abc2idx[cls_name])\n",
    "                img_idx = batch_idx * val_loader.batch_size + i\n",
    "                img_path, _ = val_dataset.samples[img_idx]\n",
    "                valid_paths.append(img_path)\n",
    "\n",
    "        if not valid_indices:\n",
    "            continue\n",
    "\n",
    "        valid_images = images[valid_indices]\n",
    "        valid_labels_idx = torch.tensor(valid_labels_idx).to(device)\n",
    "        valid_outputs = outputs[valid_indices]\n",
    "\n",
    "        # top-1\n",
    "        _, pred1 = valid_outputs.max(1)\n",
    "        correct_mask1 = pred1.eq(valid_labels_idx)\n",
    "        for idx, is_correct in enumerate(correct_mask1.cpu()):\n",
    "            if is_correct:\n",
    "                correct_top1_paths.append(valid_paths[idx])\n",
    "\n",
    "        # top-5\n",
    "        _, pred5 = valid_outputs.topk(5, 1, True, True)\n",
    "        correct_mask5 = pred5.eq(valid_labels_idx.view(-1,1)).any(dim=1)\n",
    "        for idx, is_correct in enumerate(correct_mask5.cpu()):\n",
    "            if is_correct:\n",
    "                correct_top5_paths.append(valid_paths[idx])\n",
    "\n",
    "        correct1 += correct_mask1.sum().item()\n",
    "        correct5 += correct_mask5.sum().item()\n",
    "        total += len(valid_indices)\n",
    "\n",
    "print(f\"Top-1 Accuracy: {100 * correct1 / total:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {100 * correct5 / total:.2f}%\")\n",
    "\n",
    "# 正解画像パスをファイルに保存\n",
    "with open(\"correct_top1_images.txt\", \"w\") as f:\n",
    "    for path in correct_top1_paths:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "with open(\"correct_top5_images.txt\", \"w\") as f:\n",
    "    for path in correct_top5_paths:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"Top-1で正解した画像数: {len(correct_top1_paths)}\")\n",
    "print(f\"Top-5で正解した画像数: {len(correct_top5_paths)}\")\n",
    "# ...existing code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd38c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     50\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m---> 51\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m cls_name \u001b[38;5;241m=\u001b[39m get_class_from_path(path)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cls_name \u001b[38;5;129;01min\u001b[39;00m name_to_idx \u001b[38;5;129;01mand\u001b[39;00m pred \u001b[38;5;241m==\u001b[39m name_to_idx[cls_name]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 変換は元と同じ\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# モデル\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# クラス名→index辞書\n",
    "with open(\"imagenet_class_index_lower.json\", \"r\") as f:\n",
    "    class_idx = json.load(f)\n",
    "name_to_idx = {}\n",
    "for k, v in class_idx.items():\n",
    "    idx = int(k)\n",
    "    synset, name = v\n",
    "    norm_name = name.replace(\" \", \"_\")\n",
    "    name_to_idx[norm_name] = idx\n",
    "\n",
    "# 画像パスリストを読み込む\n",
    "with open(\"correct_top1_images.txt\") as f:\n",
    "    image_paths = [line.strip() for line in f]\n",
    "\n",
    "# パスからクラス名を取得する関数\n",
    "def get_class_from_path(path):\n",
    "    # 例: ./imagenet-256/abacus/xxx.jpg → abacus\n",
    "    return os.path.basename(os.path.dirname(path))\n",
    "\n",
    "# 検証\n",
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "for path in tqdm(image_paths, desc=\"Re-evaluating\", unit=\"img\"):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred1 = output.argmax(1).item()\n",
    "        _, pred5 = output.topk(5, 1, True, True)\n",
    "        pred5 = pred5.cpu().numpy()[0]\n",
    "    cls_name = get_class_from_path(path)\n",
    "    if cls_name in name_to_idx:\n",
    "        label_idx = name_to_idx[cls_name]\n",
    "        if pred1 == label_idx:\n",
    "            correct_top1 += 1\n",
    "        if label_idx in pred5:\n",
    "            correct_top5 += 1\n",
    "\n",
    "print(f\"再分類でTop-1正解した画像数: {correct_top1}/{len(image_paths)}\")\n",
    "print(f\"再分類でTop-5正解した画像"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
